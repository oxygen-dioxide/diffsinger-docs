<a name="sTcpc"></a>
### 以下内容面对小白用户，通俗但不够准确，有兴趣可以自行搜索
<a name="ZkIMI"></a>
### 推理（Inference）
训练好的模型计算出数据的过程，比如你合成歌曲的过程
<a name="CEEXt"></a>
### 模型权重（Model weight）
模型参数的一种，指的是模型中各个参数的值 。在本教程中通常指训练好的模型
<a name="eNPGB"></a>
### 数据集
数据的集合，包括训练集、验证集和测试集。
<a name="ZAKik"></a>
### 训练集
训练的主要数据来源
<a name="wGY0n"></a>
### 验证集
训练过程中评估模型性能的数据，通过对验证集进行预测，可以得到模型在新数据上的表现情况
<a name="rbhcT"></a>
### 测试集
测试集用于最终评估模型的性能，通过对测试集进行预测，可以确定模型的最终性能
<a name="yQklr"></a>
### 拟合度（Fitness）
拟合度指的是模型在训练数据集上的性能表现。<br />拟合度越高，表示模型能够较好地“模仿”训练数据<br />拟合度过低则表示模型对训练数据的“模仿”合能力不足，对新数据的预测能力也可能不足。
<a name="jHFGW"></a>
### 过拟合
训练模型时，模型在训练数据上的表现过于优异，而在未知数据上的表现不佳的情况。这种情况通常发生在模型的复杂度过高，或者训练数据不够充分时。
<a name="z9rge"></a>
#### 避免过拟合
增加训练数据的数量或在模型在验证集上表现持续下降时停止训练。
<a name="a3hqU"></a>
### 欠拟合
欠拟合指的是模型无法很好地拟合数据，导致预测的精度不够高。<br />这种情况下，模型无法很好地捕捉到数据中的特征和规律，导致预测的准确度不够高。
<a name="igezM"></a>
#### 避免欠拟合
选择适当的模型，比如增加模型的复杂度，比如增加网络层数或增加网络参数。<br />增加训练数据，或调整学习率或优化算法，提高模型的收敛速度。
<a name="X4bnT"></a>
### epoch
在模型训练中，epoch是指对训练数据集进行一轮完整的遍历和更新参数的过程。<br />模型训练时，通常需要进行多轮训练，每轮训练都叫做一个epoch。
<a name="PVxuM"></a>
### loss损失率
模型训练中的损失率是指模型预测结果与真实结果之间的差异度量。<br />通常情况下，损失率越小，模型的准确率越高，说明模型对于训练数据的拟合越好。
<a name="Hd5l2"></a>
### lr学习率
学习率是模型训练中用来控制模型参数更新步长的一个超参数。<br />它决定了模型在每次迭代中更新参数的幅度，即模型每次迭代对错误的调整程度。<br />通常情况下，学习率越大，模型的更新速度越快，但也容易错过最优解；相反，学习率越小，模型的更新速度越慢，但更容易收敛到最优解。
<a name="DF7WA"></a>
### 学习率退火
是指在模型训练过程中，随着训练的进行，逐渐降低学习率的一种策略。<br />这样可以避免模型在训练初期受到过大的更新，使模型训练更加稳定。<br />通常在模型收敛后，学习率会被逐渐降低，以防止模型过拟合
<a name="xs0Tn"></a>
### 模型蒸馏（Model dstillation）
模型蒸馏是一种模型压缩技术，它通过使用一个强大的“教师”模型来训练一个较小的“学生”模型，从而让学生模型具有更好的性能<br />使用教师模型对训练数据进行预测，得到教师模型的输出结果。<br />使用教师模型的输出结果作为标签，训练学生模型，让学生模型尽可能接近教师模型的输出结果。<br />通过模型蒸馏，可以在保持模型性能的同时减小模型的大小，提高模型的部署效率。 
